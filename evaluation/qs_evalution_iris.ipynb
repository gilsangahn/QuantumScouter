{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a6be5-ed51-4c45-8f65-0ed71c2285f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Configuration \n",
    "# Imports essential libraries for data serialization and visualization.\n",
    "\n",
    "import pickle  # Used for loading experiment data\n",
    "\n",
    "# PyTorch (Required for unpickling data containing Tensors)\n",
    "import torch\n",
    "\n",
    "# Matplotlib for plotting training results\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c11969-ccce-4a57-8fc6-187ebf8f03c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Device Configuration\n",
    "# Checks if a CUDA-enabled GPU is available and sets the device to 'cuda' or 'cpu'.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device set to: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a227f87c-0ed7-404d-b9b0-16e3777db34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load Experiment Data (Iris)\n",
    "# Loads the training logs and performance metrics for the 'Iris' classification task.\n",
    "\n",
    "with open('reward_ep_list_iris.pkl', 'rb') as file: reward_ep_list = pickle.load(file)\n",
    "with open('reward_sum_ep_list_iris.pkl', 'rb') as file: reward_sum_ep_list = pickle.load(file)\n",
    "with open('obs_ep_list_iris.pkl', 'rb') as file: obs_ep_list = pickle.load(file)\n",
    "with open('outs_ep_list_iris.pkl', 'rb') as file: outs_ep_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f7aee-bfd2-4b11-86f5-1b6a3eed44ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Cumulative Reward Visualization\n",
    "# Visualizes the cumulative reward trend across all episodes for the Iris task.\n",
    "\n",
    "# Generate x-axis indices corresponding to each episode\n",
    "x = [x for x in range(len(reward_sum_ep_list))] \n",
    "\n",
    "# Plot the cumulative rewards as a scatter plot\n",
    "# Note: Converts tensors to CPU memory ([t.cpu()...]) to ensure compatibility with Matplotlib.\n",
    "plt.scatter(x, [t.cpu() for t in reward_sum_ep_list], alpha=0.3, s=10)\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('p1.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Episode Reward Visualization\n",
    "# Visualizes the reward obtained in each episode for the Iris task.\n",
    "\n",
    "# Plot the episode rewards as a scatter plot.\n",
    "# Note: Converts GPU tensors to CPU memory ([t.cpu()...]) for compatibility with Matplotlib.\n",
    "plt.scatter(x, [t.cpu() for t in reward_ep_list], alpha=0.3, s=10)\n",
    "\n",
    "# Save the plot as a high-resolution image\n",
    "plt.savefig('p2.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382929e5-5aad-460d-83ec-09f13c8b3633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Best Reward Identification (Iris)\n",
    "# Identifies the maximum reward achieved and the corresponding episode index for the Iris task.\n",
    "\n",
    "m_val = max(reward_ep_list)\n",
    "reward_ep_list.index(m_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca6ff3e-2834-439f-895b-bb79fd62fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Best Episode Optimization Log\n",
    "# Displays the optimization history with clear column names.\n",
    "\n",
    "# Find the index of the best episode\n",
    "best_idx = reward_ep_list.index(m_val)\n",
    "best_data = outs_ep_list[best_idx]\n",
    "\n",
    "print(f\"Best Episode Index: {best_idx}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Opt Step':<10} | {'Cost (Loss)':<15} | {'Train Acc':<12} | {'Test Acc':<12}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for step_data in best_data:\n",
    "    \n",
    "    # 1. Iteration\n",
    "    it_val = int(step_data[0]) if not isinstance(step_data[0], torch.Tensor) else int(step_data[0].item())\n",
    "    \n",
    "    # 2. Cost\n",
    "    cost_val = step_data[1] if not isinstance(step_data[1], torch.Tensor) else step_data[1].item()\n",
    "    \n",
    "    # 3. Train Accuracy\n",
    "    train_acc = step_data[2] if not isinstance(step_data[2], torch.Tensor) else step_data[2].item()\n",
    "    \n",
    "    # 4. Test Accuracy\n",
    "    # Check if the 4th element exists to avoid errors\n",
    "    if len(step_data) > 3:\n",
    "        test_acc = step_data[3] if not isinstance(step_data[3], torch.Tensor) else step_data[3].item()\n",
    "    else:\n",
    "        test_acc = 0.0\n",
    "\n",
    "    print(f\"{it_val:<10} | {cost_val:<15.6f} | {train_acc:<12.4f} | {test_acc:<12.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa35006-504d-4ac0-ac57-a41ec8954066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Best Episode Observations\n",
    "# Displays the sequence of observations (states) encountered by the agent during the best performing episode.\n",
    "\n",
    "print(obs_ep_list[reward_ep_list.index(m_val)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
