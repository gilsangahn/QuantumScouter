{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971b6bd-869a-45a1-9cf9-9b611b5551b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device name: NVIDIA GeForce RTX 4060 Ti\n",
      "Torch CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Environment Setup and Configuration\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "import numpy as np\n",
    "from pennylane.templates.layers import StronglyEntanglingLayers\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# Check for CUDA availability to enable GPU acceleration\n",
    "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Torch CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185a30a4-afc7-461f-8b18-33a161fd6457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Initialize Quantum Device\n",
    "# Using 'lightning.qubit' for high-performance state-vector simulation.\n",
    "# 'shots=None' indicates exact analytical expectation values (ideal simulation).\n",
    "dev = qml.device(\"lightning.qubit\", wires=6, shots=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafce97e-f8cc-4b54-a0f2-4dfea4ee303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Parameter Counting Helper\n",
    "# Counts the number of rotation gates in the gatestream to determine parameter size.\n",
    "\n",
    "def check_np(list):\n",
    "    \"\"\"\n",
    "    Counts the number of parameterized gates (Rotations) in the gate sequence.\n",
    "    Args:\n",
    "        list: The gatestream (list of gates).\n",
    "    Returns:\n",
    "        num: Total number of rotation parameters required.\n",
    "    \"\"\"\n",
    "    num = 0\n",
    "    for r in list:\n",
    "        # Check if the gate is a rotation type (\"Rot\")\n",
    "        if r[0] == \"Rot\": \n",
    "            num += 1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70b326-5691-4111-b9de-c5adb44eac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dynamic Ansatz Construction (RL-driven)\n",
    "# Constructs the variational circuit based on the gate sequence (gatestream) provided by the RL agent.\n",
    "\n",
    "def ansatz(W, gatestream):\n",
    "    \"\"\"\n",
    "    Builds the quantum circuit dynamically.\n",
    "    Args:\n",
    "        W: Trainable parameters for rotation gates.\n",
    "        gatestream: List of gates (Action history from RL agent).\n",
    "    \"\"\"\n",
    "    w_cnt = 0\n",
    "    for gate in gatestream:\n",
    "        # If the gate is a parameterized rotation\n",
    "        if gate[0] == \"Rot\":\n",
    "            # Apply Pauli Rotation: Param W[w_cnt], Axis gate[1], Target wire gate[2]\n",
    "            qml.PauliRot(W[w_cnt], gate[1], wires=gate[2])\n",
    "            w_cnt += 1\n",
    "\n",
    "        # If the gate is CNOT (Entanglement)\n",
    "        elif gate[0] == \"CNOT\":\n",
    "            qml.CNOT(wires=[gate[1], gate[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9e349-edc0-4671-902c-7d4d35a1a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: State Preparation\n",
    "# Encodes classical input data into quantum states.\n",
    "\n",
    "def statepreparation(x):\n",
    "    \"\"\"\n",
    "    Embeds the input feature vector x into the quantum state amplitudes.\n",
    "    Method: Amplitude Embedding (requires normalized input).\n",
    "    \"\"\"\n",
    "    qml.AmplitudeEmbedding(x, wires=range(6), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d31402-5d6d-4607-8493-ec6f875b98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Quantum Circuit Execution (QNode)\n",
    "# Defines the full quantum circuit pipeline: Encoding -> Fixed Entanglement -> Dynamic RL Ansatz -> Measurement.\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\", diff_method=\"adjoint\")\n",
    "def circuit(weights_ent, weights_rl, x, gatestream):\n",
    "    \"\"\"\n",
    "    Executes the quantum circuit.\n",
    "    Args:\n",
    "        weights_ent: Parameters for the fixed StronglyEntanglingLayers.\n",
    "        weights_rl: Parameters for the dynamic gates determined by the RL agent.\n",
    "        x: Input feature vector.\n",
    "        gatestream: Sequence of gates (architecture) defined by the RL agent.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. State Preparation (Data Encoding)\n",
    "    statepreparation(x)\n",
    "    \n",
    "    # 2. Fixed Entanglement Layer (Pre-processing)\n",
    "    # Provides a base level of entanglement using StronglyEntanglingLayers.\n",
    "    StronglyEntanglingLayers(weights_ent, wires=range(6))\n",
    "    \n",
    "    # 3. Dynamic Ansatz (RL-Constructed)\n",
    "    # Applies the specific sequence of gates generated by the RL agent.\n",
    "    ansatz(weights_rl, gatestream)\n",
    "\n",
    "    # 4. Measurement\n",
    "    # Returns the expectation value of the Pauli-Z operator on the first qubit.\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee6039f-df2f-44b5-b51b-a1a85d7d07db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Hybrid Variational Classifier\n",
    "# Combines the quantum circuit output with a classical bias parameter.\n",
    "\n",
    "def variational_classifier(weights_ent, weights_rl, bias, x, gatestream):\n",
    "    \"\"\"\n",
    "    Computes the final prediction of the hybrid model.\n",
    "    Formula: f(x) = <Z> + b\n",
    "    Args:\n",
    "        weights_ent: Parameters for fixed entanglement.\n",
    "        weights_rl: Parameters for RL-generated gates.\n",
    "        bias: Classical bias term.\n",
    "        x: Input data.\n",
    "        gatestream: Quantum circuit architecture.\n",
    "    \"\"\"\n",
    "    return circuit(weights_ent, weights_rl, x, gatestream) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0e2408-a9eb-4244-9b58-c114e6e6f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Mean Squared Error (MSE) Loss\n",
    "# Standard loss function for regression-based quantum classification.\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    \"\"\"\n",
    "    Computes the Mean Squared Error between labels and predictions.\n",
    "    Includes tensor type/device compatibility checks.\n",
    "    \"\"\"\n",
    "    # Ensure predictions are a tensor\n",
    "    preds  = torch.stack(predictions).squeeze() if isinstance(predictions, list) else predictions\n",
    "    # Match label tensor properties to predictions\n",
    "    labels = torch.as_tensor(labels, dtype=preds.dtype, device=preds.device).squeeze()\n",
    "    \n",
    "    # Calculate Mean Squared Error\n",
    "    return ((labels - preds) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e94555-4060-4d6f-b96e-ab319febcf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Classification Accuracy (Sign-based)\n",
    "# Measures accuracy by comparing the sign of predictions with true labels {-1, 1}.\n",
    "\n",
    "def accuracy_sign(labels, predictions):\n",
    "    \"\"\"\n",
    "    Computes accuracy for binary classification.\n",
    "    Method: Sign thresholding (pred >= 0 -> Class 1, else -> Class -1).\n",
    "    Args:\n",
    "        labels: True labels tensor.\n",
    "        predictions: Model output tensor (expectation values).\n",
    "    \"\"\"\n",
    "    # Ensure tensor compatibility\n",
    "    preds  = torch.stack(predictions).squeeze() if isinstance(predictions, list) else predictions\n",
    "    labels = labels.to(dtype=preds.dtype, device=preds.device).squeeze()\n",
    "    \n",
    "    # Convert continuous predictions to discrete class labels {1.0, -1.0}\n",
    "    pred_labels = torch.where(preds >= 0, 1.0, -1.0)\n",
    "    \n",
    "    # Calculate mean accuracy\n",
    "    return (pred_labels == labels).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f49c77-4c91-47be-8af5-19cec5c0560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Cost Function Calculation\n",
    "# Computes the total cost (loss) over a batch of data by aggregating individual predictions.\n",
    "\n",
    "def cost(weights_ent, weights_rl, bias, X, Y, gatestream):\n",
    "    \"\"\"\n",
    "    Calculates the loss for a given dataset batch.\n",
    "    Args:\n",
    "        X: Batch of input data.\n",
    "        Y: Batch of true labels.\n",
    "        gatestream: Circuit structure.\n",
    "    \"\"\"\n",
    "    # Generate predictions for each sample in the batch\n",
    "    predictions = [variational_classifier(weights_ent, weights_rl, bias, x, gatestream) for x in X]\n",
    "    \n",
    "    # Calculate Square Loss\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a8ad46-cbea-443f-acca-53397c562712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Circuit Optimization Function (Reward Calculation)\n",
    "# Trains the specific circuit architecture proposed by the RL agent to evaluate its performance.\n",
    "\n",
    "def opt_classifier(gatestream, weights_ent=None, iters=15, draw=False):\n",
    "    \"\"\"\n",
    "    Performs short-term training (optimization) of the quantum circuit.\n",
    "    Args:\n",
    "        gatestream: Circuit architecture from RL agent.\n",
    "        weights_ent: Initial weights for SEL (transfer learning context).\n",
    "        iters: Number of optimization steps (epochs/iterations).\n",
    "        draw: Boolean flag to return the circuit diagram.\n",
    "    Returns:\n",
    "        out_list: Training logs [iter, cost, train_acc, val_acc].\n",
    "        draw_p: Circuit visual (text based).\n",
    "        figset: Data and weights snapshots.\n",
    "        weights_ent: Updated SEL weights.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load Dataset (Updated path consistency)\n",
    "    # Assumes data is in 'dataset' folder\n",
    "    import os\n",
    "    X = torch.from_numpy(np.load(os.path.join(\"dataset\", \"data_speck.npy\"))).float()\n",
    "    Y = torch.from_numpy(np.load(os.path.join(\"dataset\", \"labels_speck.npy\"))).float()\n",
    "    Y = Y * 2 - 1 # Rescale labels from [0, 1] to [-1, 1] for Pauli-Z expectation\n",
    "\n",
    "    # Reproducibility\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # Data Splitting (80% Train, 20% Validation)\n",
    "    num_data = len(Y)\n",
    "    num_train = int(0.8 * num_data)\n",
    "    indices = torch.randperm(num_data, device=Y.device) # Random permutation\n",
    "    X_train = X[indices[:num_train]]\n",
    "    Y_train = Y[indices[:num_train]]\n",
    "    X_val   = X[indices[num_train:]]\n",
    "    Y_val   = Y[indices[num_train:]]\n",
    "\n",
    "    dev_t = X.device # Detect device (CPU/GPU)\n",
    "\n",
    "    # Initialize or Load Weights for Entanglement Layer\n",
    "    if weights_ent is None:\n",
    "        weights_ent = torch.randn((2, 6, 3), device=dev_t) * 0.01\n",
    "    else:\n",
    "        weights_ent = weights_ent.to(dev_t)\n",
    "    weights_ent = weights_ent.clone().detach().requires_grad_(True)\n",
    "\n",
    "    # Initialize Weights for RL-Generated Ansatz\n",
    "    num_rot_params = check_np(gatestream) # Count required parameters\n",
    "    if num_rot_params > 0:\n",
    "        weights_rl = (torch.randn(num_rot_params, device=dev_t) * 0.01).requires_grad_(True)\n",
    "    else:\n",
    "        weights_rl = torch.zeros(0, device=dev_t, requires_grad=True)\n",
    "\n",
    "    # Classical Bias\n",
    "    bias = torch.tensor(0.0, device=dev_t, requires_grad=True)\n",
    "\n",
    "    # Optimizer (SGD with Momentum)\n",
    "    opt = torch.optim.SGD([weights_ent, weights_rl, bias], lr=0.01, momentum=0.9)\n",
    "    batch_size = 10\n",
    "\n",
    "    out_list = []\n",
    "\n",
    "    # Optimization Loop\n",
    "    for it in range(iters):\n",
    "\n",
    "        # Mini-batch Selection\n",
    "        batch_idx = torch.randint(0, num_train, (batch_size,), device=dev_t)\n",
    "        X_batch, Y_batch = X_train[batch_idx], Y_train[batch_idx]\n",
    "\n",
    "        # Update Step\n",
    "        opt.zero_grad()\n",
    "        loss = cost(weights_ent, weights_rl, bias, X_batch, Y_batch, gatestream)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # Evaluation (No Gradients)\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Training Metrics\n",
    "            vals_tr  = [variational_classifier(weights_ent, weights_rl, bias, x, gatestream) for x in X_train]\n",
    "            preds_tr = torch.stack(vals_tr).squeeze()\n",
    "            acc_train = (torch.sign(preds_tr) == torch.sign(Y_train)).float().mean()\n",
    "\n",
    "            # Validation Metrics\n",
    "            vals_val  = [variational_classifier(weights_ent, weights_rl, bias, x, gatestream) for x in X_val]\n",
    "            preds_val = torch.stack(vals_val).squeeze()\n",
    "            acc_val   = (torch.sign(preds_val) == torch.sign(Y_val)).float().mean()\n",
    "            cost_val  = ((Y_val - preds_val) ** 2).mean()\n",
    "\n",
    "        # Log Progress\n",
    "        out_list.append([it + 1, float(cost_val), float(acc_train), float(acc_val)])\n",
    "\n",
    "        # Early Stopping Condition (Threshold for Success)\n",
    "        if float(acc_val) >= 0.65:\n",
    "            break\n",
    "\n",
    "    # Circuit Drawing (Optional)\n",
    "    if draw and len(X_val) > 0:\n",
    "        x_draw     = X_val[0].detach().cpu().numpy()\n",
    "        w_ent_draw = weights_ent.detach().cpu().numpy()\n",
    "        w_rl_draw  = weights_rl.detach().cpu().numpy()\n",
    "        draw_p = qml.draw(circuit)(w_ent_draw, w_rl_draw, x_draw, gatestream)\n",
    "    else:\n",
    "        draw_p = None    \n",
    "\n",
    "    # Snapshot of Data and Weights\n",
    "    figset = [weights_ent.detach(), weights_rl.detach(), bias.detach(), X_train, Y_train, X_val, Y_val]\n",
    "    \n",
    "    return out_list, draw_p, figset, weights_ent.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50641228-1aef-4d19-8266-26d4b24c1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Gate to Observation Vector Conversion\n",
    "# Encodes symbolic gate representations into numerical observation vectors for the RL agent.\n",
    "# Encoding format: [is_Rotation, is_CNOT, Property_1 (Axis/Control), Property_2 (Target)]\n",
    "\n",
    "def gate_to_obs(gate):\n",
    "    \"\"\"\n",
    "    Converts a gate tuple into a fixed-size observation vector.\n",
    "    Args:\n",
    "        gate: Tuple describing the gate (e.g., ('Rot', 'X', 0) or ('CNOT', 0, 1)).\n",
    "    Returns:\n",
    "        ob: List [Type_Rot, Type_CNOT, Param1, Param2].\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize observation vector\n",
    "    ob = [0, 0, 0, 0]\n",
    "    \n",
    "    # Case 1: Rotation Gate\n",
    "    if gate[0] == 'Rot':\n",
    "        ob[0] = 1 # Set Rotation flag\n",
    "        \n",
    "        # Encode Rotation Axis (X=1, Y=2, Z=3)\n",
    "        if gate[1] == 'X': ob[2] = 1\n",
    "        elif gate[1] == 'Y': ob[2] = 2\n",
    "        elif gate[1] == 'Z': ob[2] = 3\n",
    "        \n",
    "        ob[3] = gate[2] # Target wire index\n",
    "    \n",
    "    # Case 2: CNOT Gate\n",
    "    elif gate[0] == 'CNOT':\n",
    "        ob[1] = 1 # Set CNOT flag\n",
    "        ob[2] = gate[1] # Control wire index\n",
    "        ob[3] = gate[2] # Target wire index\n",
    "    \n",
    "    return ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36dceb4-ea56-4921-9a30-433cd0dd0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Environment State Update\n",
    "# Updates the internal state (gatestream and observation history) based on the agent's selected action.\n",
    "\n",
    "def update_obs(act, step, obs, gatestream, gates):\n",
    "    \"\"\"\n",
    "    Updates the environment state after an action is performed.\n",
    "    Args:\n",
    "        act: Index of the selected action from the 'gates' list.\n",
    "        step: Current time step index.\n",
    "        obs: Current observation history (state buffer).\n",
    "        gatestream: List of gates currently in the circuit.\n",
    "        gates: List of all available candidate gates.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Update Circuit Architecture\n",
    "    gatestream.append(gates[act]) # Append the selected gate to the circuit\n",
    "    \n",
    "    # 2. Update Observation Vector\n",
    "    ob = gate_to_obs(gates[act])  # Convert the gate info to a numerical observation\n",
    "    obs[step] = ob                # Record the observation at the current step\n",
    "    step += 1                     # Increment step counter\n",
    "\n",
    "    return step, obs, gatestream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f7005-29a4-4b1c-b9bb-a0a299a37961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Reward Function Definition\n",
    "# Calculates the multi-objective reward signal for the RL agent.\n",
    "# Components: Accuracy, Cost, Gate Distribution (Variance), Redundancy (Duplicate), Connectivity, and Circuit Depth.\n",
    "\n",
    "def cal_reward(steps, obs, outs):\n",
    "    \"\"\"\n",
    "    Computes the reward for the current step based on circuit performance and structural constraints.\n",
    "    Args:\n",
    "        steps: Current step count in the episode.\n",
    "        obs: Observation history (sequence of gates applied).\n",
    "        outs: Optimization logs containing [iter, cost, train_acc, val_acc].\n",
    "    Returns:\n",
    "        list: Individual reward components.\n",
    "        float: Total weighted reward.\n",
    "    \"\"\"\n",
    "\n",
    "    ## 1. Accuracy Reward\n",
    "    # Calculate average validation accuracy from the optimization trajectory.\n",
    "    acc = [row[2] for row in outs]\n",
    "    acc_m = sum(acc) / len(acc)\n",
    "\n",
    "    ## 2. Cost Reward\n",
    "    # Inverse of the average loss (Lower loss -> Higher reward).\n",
    "    cost = [row[1] for row in outs]\n",
    "    cost_m = 1 / (sum(cost) / len(cost))\n",
    "\n",
    "    ## 3. Qubit Usage Variance Reward\n",
    "    # Encourages uniform distribution of gates across all qubits (prevents neglecting specific qubits).\n",
    "    pop_list = [0, 0, 0, 0, 0, 0] # Counter for each qubit (0~5)\n",
    "    for row in obs:\n",
    "        if row[1] == 1: # If CNOT gate\n",
    "            pop_list[row[2]] += 1 # Control qubit\n",
    "            pop_list[row[3]] += 1 # Target qubit\n",
    "        elif row[0] == 1: # If Rotation gate\n",
    "            pop_list[row[3]] += 1 # Target qubit\n",
    "    \n",
    "    # Calculate score based on variance (Low variance = High score)\n",
    "    pop_r = (2 - np.var(pop_list)) / 2    \n",
    "\n",
    "    ## 4. Redundancy Penalty (Duplicate Check)\n",
    "    # Penalizes consecutive identical operations on the same qubits to avoid redundant cycles.\n",
    "    dup_r = 0\n",
    "    \n",
    "    # Case A: Current gate is Rotation\n",
    "    if obs[steps-1][0] == 1:\n",
    "        tc = obs[steps-1][3] # Target qubit index\n",
    "        tc_list = []\n",
    "        # Filter history for gates involving this qubit\n",
    "        for row in obs:\n",
    "            if row[1] == 1:\n",
    "                if row[2] == tc or row[3] == tc: tc_list.append(row)\n",
    "            elif row[0] == 1:\n",
    "                if row[3] == tc: tc_list.append(row)\n",
    "        \n",
    "        # Check if the last two operations are identical\n",
    "        if len(tc_list) > 1:\n",
    "            if tc_list[-1] == tc_list[-2]: dup_r = -10\n",
    "            \n",
    "    # Case B: Current gate is CNOT\n",
    "    elif obs[steps-1][1] == 1:\n",
    "        # Check history for Control Qubit\n",
    "        tc = obs[steps-1][2]\n",
    "        tc_list_c = []\n",
    "        for row in obs:\n",
    "            if row[1] == 1:\n",
    "                if row[2] == tc or row[3] == tc: tc_list_c.append(row)\n",
    "            elif row[0] == 1:\n",
    "                if row[3] == tc: tc_list_c.append(row)\n",
    "        \n",
    "        # Check history for Target Qubit\n",
    "        tc = obs[steps-1][3]\n",
    "        tc_list_t = []\n",
    "        for row in obs:\n",
    "            if row[1] == 1:\n",
    "                if row[2] == tc or row[3] == tc: tc_list_t.append(row)\n",
    "            elif row[0] == 1:\n",
    "                if row[3] == tc: tc_list_t.append(row)\n",
    "        \n",
    "        # Apply penalty if redundancy is detected in both control and target histories\n",
    "        if len(tc_list_c) > 1 and len(tc_list_t) > 1:\n",
    "            if tc_list_c[-1] == tc_list_c[-2] and tc_list_t[-1] == tc_list_t[-2]: dup_r = -10\n",
    "\n",
    "    ## 5. Gate Type Reward\n",
    "    # Incentivizes specific gate types (Rotation vs CNOT).\n",
    "    if obs[steps-1][0] == 1: # If Rotation\n",
    "        gate_r = 1\n",
    "        rot_r = 1\n",
    "    else:\n",
    "        gate_r = 0\n",
    "        rot_r = 0\n",
    "\n",
    "    ## 6. Connectivity Reward (CNOT Distance)\n",
    "    # Encourages local connectivity (shorter distance between control and target).\n",
    "    if obs[steps-1][1] == 1:   \n",
    "        cnot_r = 1 / abs(obs[steps-1][2]-obs[steps-1][3])\n",
    "    else: cnot_r = 0    \n",
    "\n",
    "    ## 7. Circuit Depth Efficiency\n",
    "    # Penalizes longer circuits (Encourages finding solutions with fewer steps).\n",
    "    steps_r = (30 - steps) / 30\n",
    "    \n",
    "    # Return component list and final weighted sum\n",
    "    # Weighted Sum Formula: Accuracy * 30 + Cost * 2 + Variance * 3 + Steps * 5 + ...\n",
    "    return [acc_m, cost_m, gate_r, rot_r, cnot_r, steps_r, pop_r, dup_r], \\\n",
    "           (acc_m - 0.5)*2 * 15 + cost_m * 2 + gate_r * 3 + rot_r + cnot_r + steps_r * 5 + pop_r * 3 + dup_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1558c-0e6a-4890-b20a-a6d7072dd28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Quantum Architecture Search Environment (RL Environment)\n",
    "# Defines the interaction environment for the RL agent, including action space,\n",
    "# state transitions, reward calculation, and termination conditions.\n",
    "\n",
    "class qc:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the environment.\n",
    "        Defines the Action Space (Gate Pool) and Maximum Circuit Depth.\n",
    "        \"\"\"\n",
    "        # Define Action Space: Pool of available gates\n",
    "        # - Rotations (X, Y, Z) on all 6 qubits\n",
    "        # - CNOTs on all possible connected pairs\n",
    "        self.gates = [['Rot','X', 0], ['Rot','X', 1], ['Rot','X', 2], ['Rot','X', 3], ['Rot','X', 4], ['Rot','X', 5],\n",
    "         ['Rot','Y', 0], ['Rot','Y', 1], ['Rot','Y', 2], ['Rot','Y', 3], ['Rot','Y', 4], ['Rot','Y', 5],\n",
    "         ['Rot','Z', 0], ['Rot','Z', 1], ['Rot','Z', 2], ['Rot','Z', 3], ['Rot','Z', 4], ['Rot','Z', 5],\n",
    "         ['CNOT', 0, 1],  ['CNOT', 0, 2],  ['CNOT', 0, 3], ['CNOT', 0, 4], ['CNOT', 0, 5],\n",
    "         ['CNOT', 1, 0],  ['CNOT', 1, 2],  ['CNOT', 1, 3], ['CNOT', 1, 4], ['CNOT', 1, 5],\n",
    "         ['CNOT', 2, 0],  ['CNOT', 2, 1],  ['CNOT', 2, 3], ['CNOT', 2, 4], ['CNOT', 2, 5],\n",
    "         ['CNOT', 3, 0],  ['CNOT', 3, 1],  ['CNOT', 3, 2], ['CNOT', 3, 4], ['CNOT', 3, 5],\n",
    "         ['CNOT', 4, 0],  ['CNOT', 4, 1],  ['CNOT', 4, 2], ['CNOT', 4, 3], ['CNOT', 4, 5],\n",
    "         ['CNOT', 5, 0],  ['CNOT', 5, 1],  ['CNOT', 5, 2], ['CNOT', 5, 3], ['CNOT', 5, 4]] \n",
    "        \n",
    "        self.len_qc = 30 # Maximum number of steps (max circuit depth)\n",
    "        self.act_space = len(self.gates) # Size of the action space\n",
    "    \n",
    "        self.weights_ent = None # Weights for the fixed entanglement layer\n",
    "\n",
    "    def reset(self, weights_ent=None):\n",
    "        \"\"\"\n",
    "        Resets the environment to the initial state.\n",
    "        Args:\n",
    "            weights_ent: Optional pre-trained weights for the SEL layer (Transfer Learning).\n",
    "        \"\"\"\n",
    "        self.steps = 0\n",
    "        self.obs = [[0] * 4 for _ in range(self.len_qc)] # Reset observation buffer\n",
    "        self.gatestream = [] # Reset circuit architecture\n",
    "        self.reward = -1\n",
    "        self.term = -1 # Termination flag\n",
    "        self.done = 0  # Success flag (Accuracy threshold met)\n",
    "        \n",
    "        # Initialize SEL weights (Random initialization or Load provided weights)\n",
    "        if weights_ent is not None:\n",
    "            self.weights_ent = weights_ent.detach().clone()\n",
    "        elif self.weights_ent is None:\n",
    "            self.weights_ent = (torch.randn((2, 6, 3)) * 0.01).detach()\n",
    "        return\n",
    "\n",
    "    def step(self, act):\n",
    "        \"\"\"\n",
    "        Executes one time step within the environment.\n",
    "        1. Updates the circuit with the selected action.\n",
    "        2. Optimizes the new circuit (Short-term training).\n",
    "        3. Calculates the reward based on performance and structure.\n",
    "        4. Checks for termination (Max steps or Target accuracy).\n",
    "        \"\"\"\n",
    "        # Validate action index\n",
    "        if act > self.act_space-1 or act < 0:\n",
    "            print(\"out of action space\")\n",
    "            return 0\n",
    "        \n",
    "        # Check if max steps reached\n",
    "        if self.steps > self.len_qc-1:\n",
    "            print(\"out of qc length\")\n",
    "            return 0\n",
    "        \n",
    "        # 1. State Update (Add gate and update observation)\n",
    "        self.steps, self.obs, self.gatestream = update_obs(act, self.steps, self.obs, self.gatestream, self.gates)\n",
    "        \n",
    "        # 2. Circuit Optimization (Evaluate current architecture)\n",
    "        self.outs, self.draw, self.figset, self.weights_ent = opt_classifier(\n",
    "            self.gatestream,\n",
    "            weights_ent=self.weights_ent,\n",
    "            iters=15, draw=False\n",
    "        )\n",
    "        \n",
    "        # 3. Reward Calculation\n",
    "        self.rlist, self.reward = cal_reward(self.steps, self.obs, self.outs)\n",
    "\n",
    "        # 4. Check Termination Conditions\n",
    "        # Terminate if max steps reached or goal achieved\n",
    "        if self.steps == self.len_qc or self.done == 1:\n",
    "            self.term = 1\n",
    "        else: self.term = 0\n",
    "\n",
    "        # Check for Early Stopping (Target Accuracy Reached)\n",
    "        acc_val_max   = max(row[3] for row in self.outs)\n",
    "        if acc_val_max >= 0.65:  # Threshold: 65% validation accuracy\n",
    "            self.done = 1\n",
    "            self.term = 1\n",
    "        \n",
    "        return 1\n",
    "\n",
    "    def gs_step(self, gs):\n",
    "        \"\"\"\n",
    "        Helper method to evaluate a specific gate stream manually.\n",
    "        Useful for debugging or validating a fixed architecture.\n",
    "        \"\"\"\n",
    "        self.outs, self.draw, self.figset, self.weights_ent = opt_classifier(\n",
    "            gs, weights_ent=self.weights_ent, iters=15, draw=False\n",
    "        )\n",
    "        return 1\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Randomly samples an action from the action space.\n",
    "        \"\"\"\n",
    "        return random.randint(0, self.act_space-1)\n",
    "    \n",
    "    def showdb(self, figset, gatestream):\n",
    "        \"\"\"\n",
    "        Visualizes the Decision Boundary using PCA.\n",
    "        Projects the high-dimensional quantum states onto 2D space.\n",
    "        \"\"\"\n",
    "        weights_ent, weights_rl, bias, X_train, Y_train, X_val, Y_val = figset\n",
    "        \n",
    "        # Combine Train and Val data for visualization\n",
    "        X_all = torch.cat([X_train, X_val], dim=0)\n",
    "        Y_all = torch.cat([Y_train, Y_val], dim=0)\n",
    "        split = len(X_train)\n",
    "\n",
    "        # Generate Predictions\n",
    "        preds = [torch.sign(variational_classifier(weights_ent, weights_rl, bias, x, gatestream)) for x in X_all]\n",
    "        preds = torch.stack(preds).squeeze().cpu().numpy()\n",
    "\n",
    "        # PCA Projection\n",
    "        from sklearn.decomposition import PCA\n",
    "        pca = PCA(n_components=2)\n",
    "        X_2d = pca.fit_transform(X_all.cpu().numpy())\n",
    "\n",
    "        # Determine Correct/Wrong predictions\n",
    "        correct = (preds == Y_all.cpu().numpy())\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.scatter(X_2d[correct, 0], X_2d[correct, 1], c=\"g\", label=\"Correct\", alpha=0.7)\n",
    "        plt.scatter(X_2d[~correct, 0], X_2d[~correct, 1], c=\"r\", label=\"Wrong\", alpha=0.7, marker=\"x\")\n",
    "    \n",
    "        # Draw vertical line separating Train (left) and Val (right) implicitly by index if sorted, \n",
    "        # or just as a visual marker for the split point in the array.\n",
    "        plt.axvline(X_2d[split, 0], color=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.title(\"Classification results (PCA 2D projection)\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
