{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136640e-e68a-47d2-82ce-aede4a2f59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "# Imports PennyLane for quantum circuit simulation and NumPy/Matplotlib for numerical operations and plotting.\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40800bf-0f2b-45a5-a527-1dd0eb8e1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Quantum Device Initialization\n",
    "# Sets up the quantum device. Uses 'lightning.gpu' for acceleration if available, otherwise falls back to CPU.\n",
    "dev = qml.device(\"lightning.gpu\", wires=2)\n",
    "# dev = qml.device(\"default.qubit\", wires=2) # Fallback option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eacd79e-d9f9-475a-8021-717ec1c757f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Parameter Counting Utility\n",
    "# Counts the number of rotation gates ('Rot') to determine the dimension of the trainable parameter vector.\n",
    "def check_np(list):\n",
    "    num = 0\n",
    "    for r in list:\n",
    "        if r[0] == \"Rot\": num += 1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1963b4d-c06e-40b4-b8a3-bc73dd612a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Ansatz Construction\n",
    "# dynamically constructs the variational quantum circuit based on the gate sequence provided by the RL agent.\n",
    "def ansatz(W, gatestream):\n",
    "    w_cnt = 0\n",
    "    for gate in gatestream:\n",
    "        # Parameterized Rotation Gate\n",
    "        if gate[0] == \"Rot\":\n",
    "            qml.PauliRot(W[w_cnt], gate[1], wires=gate[2])\n",
    "            w_cnt += 1\n",
    "        # Entangling Gate (CNOT)\n",
    "        elif gate[0] == \"CNOT\":\n",
    "            qml.CNOT(wires=[gate[1], gate[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd7e172-a681-4ea6-9565-5689e3b68ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Data Encoding (Feature Map)\n",
    "# Converts classical input features (x) into rotation angles for state preparation (Amplitude/Angle Encoding).\n",
    "def get_angles(x):\n",
    "    # Mapping logic to convert 2D/4D features into 5 rotation angles\n",
    "    beta0 = 2 * np.arcsin(np.sqrt(x[1] ** 2) / np.sqrt(x[0] ** 2 + x[1] ** 2 + 1e-12))\n",
    "    beta1 = 2 * np.arcsin(np.sqrt(x[3] ** 2) / np.sqrt(x[2] ** 2 + x[3] ** 2 + 1e-12))\n",
    "    beta2 = 2 * np.arcsin(\n",
    "        np.sqrt(x[2] ** 2 + x[3] ** 2)\n",
    "        / np.sqrt(x[0] ** 2 + x[1] ** 2 + x[2] ** 2 + x[3] ** 2)\n",
    "    )\n",
    "    return np.array([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed293ded-3e6b-4209-bb01-cc78a4cace38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: State Preparation\n",
    "# Encodes the calculated angles into the quantum state using RY rotations and CNOTs.\n",
    "def statepreparation(a):\n",
    "    qml.RY(a[0], wires=0)\n",
    "\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[1], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[2], wires=1)\n",
    "    qml.PauliX(wires=0)\n",
    "\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[3], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[4], wires=1)\n",
    "    qml.PauliX(wires=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697529c1-2c0b-4784-89dc-976981247b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Quantum Circuit Definition (QNode)\n",
    "# Combines state preparation and the ansatz to measure the expectation value.\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, angles, gatestream):\n",
    "    statepreparation(angles)\n",
    "    ansatz(weights, gatestream)\n",
    "    return qml.expval(qml.PauliZ(0)) # Measure Z-expectation on the first qubit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d4336e-e553-4018-8fd9-ad6fdded980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Variational Classifier\n",
    "# Adds a classical bias term to the quantum circuit output.\n",
    "def variational_classifier(weights, bias, angles, gatestream):\n",
    "    return circuit(weights, angles, gatestream) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5adc0-76c5-4a89-8f38-5791b1adabcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Loss Function (Square Loss)\n",
    "# Computes the Mean Squared Error (MSE) for training.\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "    loss = loss / len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6992c6-f6f1-4230-ba4f-5aaa79360207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Accuracy Metric\n",
    "# Calculates classification accuracy based on a threshold.\n",
    "def accuracy(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e8879-17ae-4859-94ab-245cb49c1094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Cost Function\n",
    "# The objective function optimized during the inner loop (hybrid training).\n",
    "def cost(weights, bias, features, labels, gatestream):\n",
    "    predictions = [variational_classifier(weights, bias, f, gatestream) for f in features]\n",
    "    return square_loss(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5bd9ee-229d-41ba-b0b8-8610f5436f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Hybrid Optimization Routine (Inner Loop)\n",
    "# Loads Iris data, pre-processes it, and trains the circuit parameters using Nesterov Momentum.\n",
    "def opt_classifier(gatestream):\n",
    "    # 1. Data Loading & Preprocessing (Iris Classes 1 & 2)\n",
    "    data = np.loadtxt(\"iris_classes1and2_scaled.txt\")\n",
    "    X = data[:, 0:2] # Use first two features\n",
    "    \n",
    "    # Padding and Normalization for Amplitude Encoding\n",
    "    padding = 0.3 * np.ones((len(X), 1))\n",
    "    X_pad = np.c_[np.c_[X, padding], np.zeros((len(X), 1))]\n",
    "    normalization = np.sqrt(np.sum(X_pad ** 2, -1))\n",
    "    X_norm = (X_pad.T / normalization).T\n",
    "    \n",
    "    # Convert features to angles\n",
    "    features = np.array([get_angles(x) for x in X_norm], requires_grad=False)\n",
    "    Y = data[:, -1]\n",
    "    \n",
    "    # 2. Train/Validation Split (75% / 25%)\n",
    "    np.random.seed(0)\n",
    "    num_data = len(Y)\n",
    "    num_train = int(0.75 * num_data)\n",
    "    index = np.random.permutation(range(num_data))\n",
    "    feats_train = features[index[:num_train]]\n",
    "    Y_train = Y[index[:num_train]]\n",
    "    feats_val = features[index[num_train:]]\n",
    "    Y_val = Y[index[num_train:]]\n",
    "    \n",
    "    X_train = X[index[:num_train]]\n",
    "    X_val = X[index[num_train:]]\n",
    "    \n",
    "    # 3. Initialization\n",
    "    weights_init = 0.01 * np.random.randn(check_np(gatestream), requires_grad=True)\n",
    "    bias_init = np.array(0.0, requires_grad=True)\n",
    "    \n",
    "    opt = NesterovMomentumOptimizer(0.01)\n",
    "    batch_size = 5\n",
    "    \n",
    "    weights = weights_init\n",
    "    bias = bias_init\n",
    "\n",
    "    out_list = []\n",
    "    \n",
    "    # 4. Training Loop (60 Iterations)\n",
    "    for it in range(60): \n",
    "        # Mini-batch sampling\n",
    "        batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "        feats_train_batch = feats_train[batch_index]\n",
    "        Y_train_batch = Y_train[batch_index]\n",
    "        \n",
    "        # Optimization Step\n",
    "        weights, bias, _, _, _ = opt.step(cost, weights, bias, feats_train_batch, Y_train_batch, gatestream)\n",
    "    \n",
    "        # Evaluation\n",
    "        predictions_train = [np.sign(variational_classifier(weights, bias, f, gatestream)) for f in feats_train]\n",
    "        predictions_val = [np.sign(variational_classifier(weights, bias, f, gatestream)) for f in feats_val]\n",
    "    \n",
    "        acc_train = accuracy(Y_train, predictions_train)\n",
    "        acc_val = accuracy(Y_val, predictions_val)\n",
    "        cost_gs = cost(weights, bias, features, Y, gatestream)\n",
    "        \n",
    "        out_list.append([it + 1, float(cost_gs), float(acc_train), float(acc_val)])\n",
    "\n",
    "        # Early Stopping Condition\n",
    "        if acc_train == 1 and acc_val == 1 and cost_gs < 0.325348: break \n",
    "\n",
    "    # 5. Visualization Preparation\n",
    "    draw_p = qml.draw(circuit)(weights, [0, 0, 0, 0, 0] ,gatestream)\n",
    "    \n",
    "    return out_list, draw_p, [weights, bias, X_train, Y_train, X_val, Y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a33e4-7103-4d16-9243-7b4e5c16dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Gate Encoding (Symbolic to Numerical)\n",
    "# Converts gate strings to numerical vectors for the RL agent.\n",
    "def gate_to_obs(gate):\n",
    "    ob = [0, 0, 0, 0]\n",
    "    if gate[0] == 'Rot':\n",
    "        ob[0] = 1\n",
    "        if gate[1] == 'X': ob[2] = 1\n",
    "        elif gate[1] == 'Y': ob[2] = 2\n",
    "        elif gate[1] == 'Z': ob[2] = 3\n",
    "        ob[3] = gate[2]\n",
    "    elif gate[0] == 'CNOT':\n",
    "        ob[1] = 1\n",
    "        ob[2] = gate[1] \n",
    "        ob[3] = gate[2] \n",
    "    return ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9070f4-8ff0-486f-b544-de56ac750b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: State Update Mechanism\n",
    "# Updates the environment state based on the selected action.\n",
    "def update_obs(act, step, obs, gatestream, gates):\n",
    "    gatestream.append(gates[act])\n",
    "    ob = gate_to_obs(gates[act])\n",
    "    obs[step] = ob\n",
    "    step += 1\n",
    "    return step, obs, gatestream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7cfd2-65f4-4f4e-8ed0-d2110ffa354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Reward Function Definition\n",
    "# Calculates the reward based on accuracy (train/val), cost, and structural constraints.\n",
    "def cal_reward(steps, obs, outs):\n",
    "    ## Accuracy Reward (Average of Train & Validation)\n",
    "    acc1 = [row[2] for row in outs]\n",
    "    acc2 = [row[3] for row in outs]\n",
    "    acc_m = ((sum(acc1) / len(acc1)) + (sum(acc2) / len(acc2))) / 2\n",
    "\n",
    "    ## Cost Reward (Inverse of Mean Cost)\n",
    "    cost = [row[1] for row in outs]\n",
    "    cost_m = 1 / (sum(cost) / len(cost))\n",
    "\n",
    "    ## Variance Reward (Uniform Gate Distribution)\n",
    "    pop_list = [0, 0] # 2 qubits\n",
    "    for row in obs:\n",
    "        if row[1] == 1:\n",
    "            pop_list[row[2]] += 1\n",
    "            pop_list[row[3]] += 1\n",
    "        elif row[0] == 1:\n",
    "            pop_list[row[3]] += 1\n",
    "    pop_r = (2 - np.var(pop_list)) / 2\n",
    "\n",
    "    ## Duplicate Gate Penalty\n",
    "    dup_r = 0\n",
    "    if obs[steps-1][0] == 1:\n",
    "        tc = obs[steps-1][3]\n",
    "        tc_list = []\n",
    "        for row in obs:\n",
    "            if row[1] == 1:\n",
    "                if row[2] == tc or row[3] == tc: tc_list.append(row)\n",
    "            elif row[0] == 1:\n",
    "                if row[3] == tc: tc_list.append(row)\n",
    "        if len(tc_list) > 1:\n",
    "            if tc_list[-1] == tc_list[-2]: dup_r = -10\n",
    "    elif obs[steps-1][1] == 1:\n",
    "        # (Similar logic for CNOTs to prevent redundant operations)\n",
    "        tc = obs[steps-1][2]\n",
    "        tc_list_c = []\n",
    "        for row in obs:\n",
    "            if row[1] == 1:\n",
    "                if row[2] == tc or row[3] == tc: tc_list_c.append(row)\n",
    "            elif row[0] == 1:\n",
    "                if row[3] == tc: tc_list_c.append(row)\n",
    "        tc = obs[steps-1][3]\n",
    "        tc_list_t = []\n",
    "        for row in obs:\n",
    "            if row[1] == 1:\n",
    "                if row[2] == tc or row[3] == tc: tc_list_t.append(row)\n",
    "            elif row[0] == 1:\n",
    "                if row[3] == tc: tc_list_t.append(row)\n",
    "        if len(tc_list_c) > 1 and len(tc_list_t) > 1:\n",
    "            if tc_list_c[-1] == tc_list_c[-2] and tc_list_t[-1] == tc_list_t[-2]: dup_r = -10\n",
    "\n",
    "    ## Gate Type Incentive (Favor Rotations)\n",
    "    if obs[steps-1][0] == 1:\n",
    "        gate_r = 1\n",
    "        rot_r = 1\n",
    "    else:\n",
    "        gate_r = 0\n",
    "        rot_r = 0\n",
    "\n",
    "    ## CNOT Distance (Locality)\n",
    "    if obs[steps-1][1] == 1:   \n",
    "        cnot_r = 1 / abs(obs[steps-1][2]-obs[steps-1][3])\n",
    "    else: cnot_r = 0    \n",
    "\n",
    "    ## Circuit Depth Penalty\n",
    "    steps_r = (42 - steps) / 42\n",
    "    \n",
    "    # Weighted Sum of Rewards\n",
    "    return [acc_m, cost_m, gate_r, rot_r, cnot_r, steps_r, pop_r, dup_r], \\\n",
    "           (acc_m - 0.5)*2 * 15 + cost_m * 2 + gate_r * 3 + rot_r + cnot_r + steps_r * 5 + pop_r * 3 + dup_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4675aea-bfb9-43ba-b0cc-8120ffccbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Quantum Circuit Environment Class\n",
    "# Defines the RL environment for the Iris classification problem.\n",
    "class qc:\n",
    "    def __init__(self):\n",
    "        # Action Space: Rotations (X, Y, Z) for 2 qubits and CNOTs\n",
    "        self.gates = [['Rot','X', 0], ['Rot','X', 1],\n",
    "                      ['Rot','Y', 0], ['Rot','Y', 1],\n",
    "                      ['Rot','Z', 0], ['Rot','Z', 1],\n",
    "                      ['CNOT', 0, 1],  ['CNOT', 1, 0]]\n",
    "        self.len_qc = 42  # Max circuit depth (e.g., 2-HE ansatz (7 gates) * 6 layers)\n",
    "        self.act_space = len(self.gates)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.steps = 0\n",
    "        self.obs = [[0] * 4 for _ in range(self.len_qc)]\n",
    "        self.gatestream = []\n",
    "        self.reward = -1\n",
    "        self.term = -1\n",
    "        self.done = 0\n",
    "        return\n",
    "\n",
    "    def step(self, act):\n",
    "        if act > self.act_space-1 or act < 0:\n",
    "            print(\"out of action space\")\n",
    "            return 0\n",
    "        if self.steps > self.len_qc-1:\n",
    "            print(\"out of qc length\")\n",
    "            return 0\n",
    "        \n",
    "        # Update State\n",
    "        self.steps, self.obs, self.gatestream = update_obs(act, self.steps, self.obs, self.gatestream, self.gates)\n",
    "        \n",
    "        # Inner Optimization Loop\n",
    "        self.outs, self.draw, self.figset = opt_classifier(self.gatestream)\n",
    "        \n",
    "        # Calculate Reward\n",
    "        self.rlist, self.reward = cal_reward(self.steps, self.obs, self.outs)\n",
    "\n",
    "        if self.steps == self.len_qc: self.term = 1\n",
    "        else: self.term = 0\n",
    "\n",
    "        # Terminate if perfect accuracy is achieved\n",
    "        if max([row[2] for row in self.outs]) == 1 and max([row[3] for row in self.outs]) == 1:\n",
    "            self.done = 1\n",
    "        \n",
    "        return 1\n",
    "\n",
    "    def gs_step(self, gs):\n",
    "        # Helper to evaluate a specific gate sequence\n",
    "        self.outs, self.draw, self.figset = opt_classifier(gs)\n",
    "        return 1\n",
    "    \n",
    "    def sample(self):\n",
    "        return random.randint(0, self.act_space-1)\n",
    "\n",
    "    def showdb(self, figset, gatestream):\n",
    "        # Visualization of Decision Boundary\n",
    "        weights = figset[0]\n",
    "        bias = figset[1]\n",
    "        X_train = figset[2]\n",
    "        Y_train = figset[3]\n",
    "        X_val = figset[4]\n",
    "        Y_val = figset[5]\n",
    "        \n",
    "        plt.figure()\n",
    "        cm = plt.cm.RdBu\n",
    "        \n",
    "        # ... (Visualization Code Omitted for Brevity, standard Matplotlib plotting)\n",
    "        # Draws contour plots and scatter plots for train/validation data\n",
    "        \n",
    "        # ... \n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
